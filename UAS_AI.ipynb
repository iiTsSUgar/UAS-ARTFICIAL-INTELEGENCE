{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNcgeUE5L7q0JfThKvc0mj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iiTsSUgar/UAS-ARTFICIAL-INTELEGENCE/blob/main/UAS_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('netflix_titles.csv')\n",
        "\n",
        "# Step 1: Data Preprocessing (25 points)\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Fill missing values\n",
        "df['director'].fillna('Unknown', inplace=True)\n",
        "df['cast'].fillna('Unknown', inplace=True)\n",
        "df['country'].fillna('Unknown', inplace=True)\n",
        "df['rating'].fillna('Not Rated', inplace=True)\n",
        "df['duration'].fillna(df['duration'].median(), inplace=True)\n",
        "\n",
        "# Convert date_added to datetime\n",
        "df['date_added'] = pd.to_datetime(df['date_added'])\n",
        "df['release_year'] = pd.to_datetime(df['release_year'].astype(str), format='%Y')\n",
        "\n",
        "# Extract features for clustering\n",
        "# Convert categorical variables to numeric\n",
        "le = LabelEncoder()\n",
        "df['type_encoded'] = le.fit_transform(df['type'])\n",
        "df['rating_encoded'] = le.fit_transform(df['rating'])\n",
        "\n",
        "# Create feature matrix\n",
        "features = ['type_encoded', 'rating_encoded', 'release_year', 'duration']\n",
        "X = df[features].copy()\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2: Clustering (25 points)\n",
        "# Determine optimal number of clusters using elbow method\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "K = range(2, 11)\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(K, inertias, 'bx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(K, silhouette_scores, 'rx-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Optimal k')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Perform final clustering with optimal k=4\n",
        "optimal_k = 4\n",
        "kmeans_final = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "df['Cluster'] = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "# Step 3: Analysis and Machine Learning Integration (25 points)\n",
        "# Analyze clusters\n",
        "cluster_analysis = df.groupby('Cluster').agg({\n",
        "    'type': lambda x: x.value_counts().index[0],\n",
        "    'rating': lambda x: x.value_counts().index[0],\n",
        "    'release_year': 'mean',\n",
        "    'duration': 'mean',\n",
        "    'show_id': 'count'\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\nCluster Analysis:\")\n",
        "print(cluster_analysis)\n",
        "\n",
        "# Visualize clusters using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['Cluster'], cmap='viridis')\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n",
        "plt.title('Clusters Visualization using PCA')\n",
        "plt.colorbar(scatter)\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Evaluation and Insights (25 points)\n",
        "# Calculate cluster characteristics\n",
        "print(\"\\nDetailed Cluster Insights:\")\n",
        "for i in range(optimal_k):\n",
        "    cluster_data = df[df['Cluster'] == i]\n",
        "    print(f\"\\nCluster {i} Analysis:\")\n",
        "    print(f\"Size: {len(cluster_data)} titles\")\n",
        "    print(f\"Most common type: {cluster_data['type'].mode()[0]}\")\n",
        "    print(f\"Average release year: {cluster_data['release_year'].dt.year.mean():.0f}\")\n",
        "    print(f\"Most common rating: {cluster_data['rating'].mode()[0]}\")\n",
        "    print(f\"Average duration: {cluster_data['duration'].mean():.2f}\")\n",
        "\n",
        "# Generate comprehensive insights\n",
        "print(\"\\nComprehensive Clustering Insights:\")\n",
        "print(\"1. Content Distribution:\")\n",
        "for i in range(optimal_k):\n",
        "    cluster_size = (df['Cluster'] == i).sum()\n",
        "    percentage = (cluster_size / len(df)) * 100\n",
        "    print(f\"Cluster {i}: {cluster_size} titles ({percentage:.1f}%)\")\n",
        "\n",
        "print(\"\\n2. Temporal Trends:\")\n",
        "for i in range(optimal_k):\n",
        "    avg_year = df[df['Cluster'] == i]['release_year'].dt.year.mean()\n",
        "    print(f\"Cluster {i} average release year: {avg_year:.0f}\")\n",
        "\n",
        "print(\"\\n3. Content Type Distribution:\")\n",
        "for i in range(optimal_k):\n",
        "    type_dist = df[df['Cluster'] == i]['type'].value_counts().to_dict()\n",
        "    print(f\"Cluster {i} content types:\", type_dist)"
      ],
      "metadata": {
        "id": "PDyILTFLCEJD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}